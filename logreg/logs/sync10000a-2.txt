[INFO] [2017-08-03 02:57:15] updater type sgd
[INFO] [2017-08-03 02:57:15] Objective type softmax
[INFO] [2017-08-03 02:57:15] Regular type L2
[INFO] [2017-08-03 02:57:15] Init local model, size [2, 54686453]
[INFO] [2017-08-03 02:57:15] updater type sgd
[INFO] [2017-08-03 02:57:15] Objective type softmax
[INFO] [2017-08-03 02:57:15] Regular type L2
[INFO] [2017-08-03 02:57:15] Init local model, size [2, 54686453]
--------------------------------------------------------------------------
[[40092,1],0]: A high-performance Open MPI point-to-point messaging module
was unable to find any relevant network interfaces:

Module: OpenFabrics (openib)
  Host: multiversohkcpu01

Another transport will be used instead, although this may result in
lower performance.
--------------------------------------------------------------------------
[INFO] [2017-08-03 02:57:15] updater type sgd
[INFO] [2017-08-03 02:57:15] Objective type softmax
[INFO] [2017-08-03 02:57:15] Regular type L2
[INFO] [2017-08-03 02:57:15] Init local model, size [2, 54686453]
[INFO] [2017-08-03 02:57:15] updater type sgd
[INFO] [2017-08-03 02:57:15] Objective type softmax
[INFO] [2017-08-03 02:57:15] Regular type L2
[INFO] [2017-08-03 02:57:15] Init local model, size [2, 54686453]
[INFO] [2017-08-03 02:57:15] updater type sgd
[INFO] [2017-08-03 02:57:15] Objective type softmax
[INFO] [2017-08-03 02:57:15] Regular type L2
[INFO] [2017-08-03 02:57:15] Init local model, size [2, 54686453]
[INFO] [2017-08-03 02:57:15] updater type sgd
[INFO] [2017-08-03 02:57:15] Objective type softmax
[INFO] [2017-08-03 02:57:15] Regular type L2
[INFO] [2017-08-03 02:57:15] Init local model, size [2, 54686453]
[INFO] [2017-08-03 02:57:15] updater type sgd
[INFO] [2017-08-03 02:57:15] Objective type softmax
[INFO] [2017-08-03 02:57:15] Regular type L2
[INFO] [2017-08-03 02:57:15] Init local model, size [2, 54686453]
[INFO] [2017-08-03 02:57:15] updater type sgd
[INFO] [2017-08-03 02:57:15] Objective type softmax
[INFO] [2017-08-03 02:57:15] Regular type L2
[INFO] [2017-08-03 02:57:15] Init local model, size [2, 54686453]
--------------------------------------------------------------------------
[[40092,1],2]: A high-performance Open MPI point-to-point messaging module
was unable to find any relevant network interfaces:

Module: OpenFabrics (openib)
  Host: multiversohkcpu03

Another transport will be used instead, although this may result in
lower performance.
--------------------------------------------------------------------------
[INFO] [2017-08-03 02:57:15] multiverso MPI-Net is initialized under MPI_THREAD_SERIALIZED mode.
[INFO] [2017-08-03 02:57:15] multiverso MPI-Net is initialized under MPI_THREAD_SERIALIZED mode.
[INFO] [2017-08-03 02:57:15] multiverso MPI-Net is initialized under MPI_THREAD_SERIALIZED mode.
[INFO] [2017-08-03 02:57:15] multiverso MPI-Net is initialized under MPI_THREAD_SERIALIZED mode.
[INFO] [2017-08-03 02:57:15] multiverso MPI-Net is initialized under MPI_THREAD_SERIALIZED mode.
[INFO] [2017-08-03 02:57:15] multiverso MPI-Net is initialized under MPI_THREAD_SERIALIZED mode.
[INFO] [2017-08-03 02:57:15] multiverso MPI-Net is initialized under MPI_THREAD_SERIALIZED mode.
[INFO] [2017-08-03 02:57:15] multiverso MPI-Net is initialized under MPI_THREAD_SERIALIZED mode.
[INFO] [2017-08-03 02:57:15] All nodes registered. System contains 8 nodes. num_worker = 8, num_server = 8
[INFO] [2017-08-03 02:57:15] Create a sync server
[INFO] [2017-08-03 02:57:15] Create a sync server
[INFO] [2017-08-03 02:57:15] Create a sync server
[INFO] [2017-08-03 02:57:15] Create a sync server
[INFO] [2017-08-03 02:57:15] Create a sync server
[INFO] [2017-08-03 02:57:15] Create a sync server
[INFO] [2017-08-03 02:57:15] Create a sync server
[INFO] [2017-08-03 02:57:15] Create a sync server
[INFO] [2017-08-03 02:57:15] Rank 0: Multiverso start successfully
[INFO] [2017-08-03 02:57:15] Rank 2: Multiverso start successfully
[INFO] [2017-08-03 02:57:15] Rank 1: Multiverso start successfully
[INFO] [2017-08-03 02:57:15] Rank 6: Multiverso start successfully
[INFO] [2017-08-03 02:57:15] Rank 4: Multiverso start successfully
[INFO] [2017-08-03 02:57:15] Rank 5: Multiverso start successfully
[INFO] [2017-08-03 02:57:15] Rank 3: Multiverso start successfully
[INFO] [2017-08-03 02:57:15] Rank 7: Multiverso start successfully
[INFO] [2017-08-03 02:57:15] SparseServer 6 create table with 13671613 elements,       offset 82029678
[INFO] [2017-08-03 02:57:15] SparseWorker 6 create SparseTable with 109372906 elements
[INFO] [2017-08-03 02:57:15] SparseServer 0 create table with 13671613 elements,       offset 0
[INFO] [2017-08-03 02:57:15] SparseWorker 0 create SparseTable with 109372906 elements
[INFO] [2017-08-03 02:57:15] SparseServer 5 create table with 13671613 elements,       offset 68358065
[INFO] [2017-08-03 02:57:15] SparseWorker 5 create SparseTable with 109372906 elements
[INFO] [2017-08-03 02:57:15] SparseServer 4 create table with 13671613 elements,       offset 54686452
[INFO] [2017-08-03 02:57:15] SparseWorker 4 create SparseTable with 109372906 elements
[INFO] [2017-08-03 02:57:15] SparseServer 1 create table with 13671613 elements,       offset 13671613
[INFO] [2017-08-03 02:57:15] SparseWorker 1 create SparseTable with 109372906 elements
[INFO] [2017-08-03 02:57:15] SparseServer 2 create table with 13671613 elements,       offset 27343226
[INFO] [2017-08-03 02:57:15] SparseWorker 2 create SparseTable with 109372906 elements
[INFO] [2017-08-03 02:57:15] SparseServer 3 create table with 13671613 elements,       offset 41014839
[INFO] [2017-08-03 02:57:15] SparseWorker 3 create SparseTable with 109372906 elements
[INFO] [2017-08-03 02:57:15] SparseServer 7 create table with 13671615 elements,       offset 95701291
[INFO] [2017-08-03 02:57:15] SparseWorker 7 create SparseTable with 109372906 elements
[INFO] [2017-08-03 02:57:15] Init ps model, size [2, 54686453]
[INFO] [2017-08-03 02:57:15] ps model with sync frequency 10000
[INFO] [2017-08-03 02:57:15] Train with file /home/hkust/rips/divkdd12.tr
[INFO] [2017-08-03 02:57:15] Init ps model, size [2, 54686453]
[INFO] [2017-08-03 02:57:15] ps model with sync frequency 10000
[INFO] [2017-08-03 02:57:15] Train with file /home/hkust/rips/divkdd12.tr
[INFO] [2017-08-03 02:57:15] Init ps model, size [2, 54686453]
[INFO] [2017-08-03 02:57:15] ps model with sync frequency 10000
[INFO] [2017-08-03 02:57:15] Train with file /home/hkust/rips/divkdd12.tr
[INFO] [2017-08-03 02:57:15] Init ps model, size [2, 54686453]
[INFO] [2017-08-03 02:57:15] ps model with sync frequency 10000
[INFO] [2017-08-03 02:57:15] Train with file /home/hkust/rips/divkdd12.tr
[INFO] [2017-08-03 02:57:15] Init ps model, size [2, 54686453]
[INFO] [2017-08-03 02:57:15] ps model with sync frequency 10000
[INFO] [2017-08-03 02:57:15] Train with file /home/hkust/rips/divkdd12.tr
[INFO] [2017-08-03 02:57:15] Init ps model, size [2, 54686453]
[INFO] [2017-08-03 02:57:15] ps model with sync frequency 10000
[INFO] [2017-08-03 02:57:15] Train with file /home/hkust/rips/divkdd12.tr
[INFO] [2017-08-03 02:57:15] Init ps model, size [2, 54686453]
[INFO] [2017-08-03 02:57:15] ps model with sync frequency 10000
[INFO] [2017-08-03 02:57:15] Train with file /home/hkust/rips/divkdd12.tr
[INFO] [2017-08-03 02:57:15] Init ps model, size [2, 54686453]
[INFO] [2017-08-03 02:57:15] ps model with sync frequency 10000
[INFO] [2017-08-03 02:57:15] Train with file /home/hkust/rips/divkdd12.tr
[INFO] [2017-08-03 02:57:19] Epoch 0. Worker 5 set 1: Sample seen 100032, train loss 0.692525, average computation time 10.244
[INFO] [2017-08-03 02:57:19] Epoch 0. Worker 4 set 1: Sample seen 100032, train loss 0.692525, average computation time 10.281
[INFO] [2017-08-03 02:57:19] Epoch 0. Worker 0 set 1: Sample seen 100032, train loss 0.692525, average computation time 10.273
[INFO] [2017-08-03 02:57:19] Epoch 0. Worker 1 set 1: Sample seen 100032, train loss 0.692525, average computation time 10.627
[INFO] [2017-08-03 02:57:19] Epoch 0. Worker 6 set 1: Sample seen 100032, train loss 0.692525, average computation time 10.274
[INFO] [2017-08-03 02:57:19] Epoch 0. Worker 7 set 1: Sample seen 100032, train loss 0.692525, average computation time 10.266
[INFO] [2017-08-03 02:57:20] Epoch 0. Worker 5 set 2: Sample seen 200064, train loss 0.692525, average computation time 10.251
[INFO] [2017-08-03 02:57:20] Epoch 0. Worker 0 set 2: Sample seen 200064, train loss 0.692525, average computation time 10.311
[INFO] [2017-08-03 02:57:20] Epoch 0. Worker 6 set 2: Sample seen 200064, train loss 0.692525, average computation time 10.268
[INFO] [2017-08-03 02:57:20] Epoch 0. Worker 2 set 1: Sample seen 100032, train loss 0.692525, average computation time 10.247
[INFO] [2017-08-03 02:57:19] Epoch 0. Worker 1 set 2: Sample seen 200064, train loss 0.692525, average computation time 10.278
[INFO] [2017-08-03 02:57:20] Epoch 0. Worker 3 set 1: Sample seen 100032, train loss 0.692525, average computation time 10.301
[INFO] [2017-08-03 02:57:20] Epoch 0. Worker 7 set 2: Sample seen 200064, train loss 0.692525, average computation time 10.261
[INFO] [2017-08-03 02:57:20] Epoch 0. Worker 2 set 2: Sample seen 200064, train loss 0.692525, average computation time 10.252
[INFO] [2017-08-03 02:57:20] Epoch 0. Worker 3 set 2: Sample seen 200064, train loss 0.692525, average computation time 10.292
[INFO] [2017-08-03 02:57:20] Epoch 0. Worker 6 set 3: Sample seen 300096, train loss 0.692525, average computation time 10.271
[INFO] [2017-08-03 02:57:21] Epoch 0. Worker 4 set 2: Sample seen 200064, train loss 0.692525, average computation time 10.285
[INFO] [2017-08-03 02:57:21] Epoch 0. Worker 5 set 3: Sample seen 300096, train loss 0.692525, average computation time 10.253
[INFO] [2017-08-03 02:57:21] Epoch 0. Worker 1 set 3: Sample seen 300096, train loss 0.692525, average computation time 10.272
[INFO] [2017-08-03 02:57:21] Epoch 0. Worker 0 set 3: Sample seen 300096, train loss 0.692525, average computation time 10.297
[INFO] [2017-08-03 02:57:21] Epoch 0. Worker 7 set 3: Sample seen 300096, train loss 0.692525, average computation time 10.260
[INFO] [2017-08-03 02:57:21] Epoch 0. Worker 2 set 3: Sample seen 300096, train loss 0.692525, average computation time 10.259
[INFO] [2017-08-03 02:57:21] Epoch 0. Worker 3 set 3: Sample seen 300096, train loss 0.692525, average computation time 10.295
[INFO] [2017-08-03 02:57:21] Epoch 0. Worker 4 set 3: Sample seen 300096, train loss 0.692525, average computation time 10.293
[INFO] [2017-08-03 02:57:22] Epoch 0. Worker 1 set 4: Sample seen 400128, train loss 0.692525, average computation time 10.270
[INFO] [2017-08-03 02:57:22] Epoch 0. Worker 5 set 4: Sample seen 400128, train loss 0.692525, average computation time 10.253
[INFO] [2017-08-03 02:57:22] Epoch 0. Worker 0 set 4: Sample seen 400128, train loss 0.692525, average computation time 10.289
[INFO] [2017-08-03 02:57:22] Epoch 0. Worker 6 set 4: Sample seen 400128, train loss 0.692525, average computation time 10.268
[INFO] [2017-08-03 02:57:22] Epoch 0. Worker 7 set 4: Sample seen 400128, train loss 0.692525, average computation time 10.260
[INFO] [2017-08-03 02:57:22] Epoch 0. Worker 2 set 4: Sample seen 400128, train loss 0.692525, average computation time 10.285
[INFO] [2017-08-03 02:57:22] Epoch 0. Worker 4 set 4: Sample seen 400128, train loss 0.692525, average computation time 10.292
[INFO] [2017-08-03 02:57:22] Epoch 0. Worker 3 set 4: Sample seen 400128, train loss 0.692525, average computation time 10.297
[INFO] [2017-08-03 02:57:23] Epoch 0. Worker 5 set 5: Sample seen 500160, train loss 0.692525, average computation time 10.251
[INFO] [2017-08-03 02:57:23] Epoch 0. Worker 1 set 5: Sample seen 500160, train loss 0.692525, average computation time 10.268
[INFO] [2017-08-03 02:57:23] Epoch 0. Worker 6 set 5: Sample seen 500160, train loss 0.692525, average computation time 10.265
[INFO] [2017-08-03 02:57:23] Epoch 0. Worker 0 set 5: Sample seen 500160, train loss 0.692525, average computation time 10.284
[INFO] [2017-08-03 02:57:23] Epoch 0. Worker 7 set 5: Sample seen 500160, train loss 0.692525, average computation time 10.260
[INFO] [2017-08-03 02:57:24] Epoch 0. Worker 2 set 5: Sample seen 500160, train loss 0.692525, average computation time 10.281
[INFO] [2017-08-03 02:57:24] Epoch 0. Worker 4 set 5: Sample seen 500160, train loss 0.692525, average computation time 10.291
[INFO] [2017-08-03 02:57:24] Epoch 0. Worker 3 set 5: Sample seen 500160, train loss 0.692525, average computation time 10.301
[INFO] [2017-08-03 02:57:25] Epoch 0. Worker 1 set 6: Sample seen 600192, train loss 0.692525, average computation time 10.326
[INFO] [2017-08-03 02:57:24] Epoch 0. Worker 6 set 6: Sample seen 600192, train loss 0.692525, average computation time 10.264
[INFO] [2017-08-03 02:57:24] Epoch 0. Worker 0 set 6: Sample seen 600192, train loss 0.692525, average computation time 10.281
[INFO] [2017-08-03 02:57:24] Epoch 0. Worker 5 set 6: Sample seen 600192, train loss 0.692525, average computation time 10.250
[INFO] [2017-08-03 02:57:25] Epoch 0. Worker 7 set 6: Sample seen 600192, train loss 0.692525, average computation time 10.261
[INFO] [2017-08-03 02:57:25] Epoch 0. Worker 4 set 6: Sample seen 600192, train loss 0.692525, average computation time 10.291
[INFO] [2017-08-03 02:57:25] Epoch 0. Worker 2 set 6: Sample seen 600192, train loss 0.692525, average computation time 10.285
[INFO] [2017-08-03 02:57:25] Epoch 0. Worker 3 set 6: Sample seen 600192, train loss 0.692525, average computation time 10.299
[INFO] [2017-08-03 02:57:25] Epoch 0. Worker 1 set 7: Sample seen 700224, train loss 0.692525, average computation time 10.317
[INFO] [2017-08-03 02:57:25] Epoch 0. Worker 6 set 7: Sample seen 700224, train loss 0.692525, average computation time 10.263
[INFO] [2017-08-03 02:57:25] Epoch 0. Worker 0 set 7: Sample seen 700224, train loss 0.692525, average computation time 10.279
[INFO] [2017-08-03 02:57:25] Epoch 0. Worker 5 set 7: Sample seen 700224, train loss 0.692525, average computation time 10.249
[INFO] [2017-08-03 02:57:26] Epoch 0. Worker 4 set 7: Sample seen 700224, train loss 0.692525, average computation time 10.290
[INFO] [2017-08-03 02:57:26] Epoch 0. Worker 7 set 7: Sample seen 700224, train loss 0.692525, average computation time 10.267
[INFO] [2017-08-03 02:57:26] Epoch 0. Worker 2 set 7: Sample seen 700224, train loss 0.692525, average computation time 10.283
[INFO] [2017-08-03 02:57:26] Epoch 0. Worker 3 set 7: Sample seen 700224, train loss 0.692525, average computation time 10.297
[INFO] [2017-08-03 02:57:26] Epoch 0. Worker 6 set 8: Sample seen 800256, train loss 0.692525, average computation time 10.262
[INFO] [2017-08-03 02:57:26] Epoch 0. Worker 1 set 8: Sample seen 800256, train loss 0.692525, average computation time 10.311
[INFO] [2017-08-03 02:57:26] Epoch 0. Worker 0 set 8: Sample seen 800256, train loss 0.692525, average computation time 10.278
[INFO] [2017-08-03 02:57:26] Epoch 0. Worker 5 set 8: Sample seen 800256, train loss 0.692525, average computation time 10.250
[INFO] [2017-08-03 02:57:27] Epoch 0. Worker 4 set 8: Sample seen 800256, train loss 0.692525, average computation time 10.289
[INFO] [2017-08-03 02:57:27] Epoch 0. Worker 7 set 8: Sample seen 800256, train loss 0.692525, average computation time 10.267
[INFO] [2017-08-03 02:57:27] Epoch 0. Worker 2 set 8: Sample seen 800256, train loss 0.692525, average computation time 10.281
[INFO] [2017-08-03 02:57:27] Epoch 0. Worker 3 set 8: Sample seen 800256, train loss 0.692525, average computation time 10.292
[INFO] [2017-08-03 02:57:27] Epoch 0. Worker 0 set 9: Sample seen 900288, train loss 0.692525, average computation time 10.276
[INFO] [2017-08-03 02:57:27] Epoch 0. Worker 6 set 9: Sample seen 900288, train loss 0.692525, average computation time 10.262
[INFO] [2017-08-03 02:57:27] Epoch 0. Worker 1 set 9: Sample seen 900288, train loss 0.692525, average computation time 10.305
[INFO] [2017-08-03 02:57:27] Epoch 0. Worker 5 set 9: Sample seen 900288, train loss 0.692525, average computation time 10.250
[INFO] [2017-08-03 02:57:27] Epoch 0. Worker 4 set 9: Sample seen 900288, train loss 0.692525, average computation time 10.287
[INFO] [2017-08-03 02:57:28] Epoch 0. Worker 7 set 9: Sample seen 900288, train loss 0.692525, average computation time 10.265
[INFO] [2017-08-03 02:57:28] Epoch 0. Worker 2 set 9: Sample seen 900288, train loss 0.692525, average computation time 10.279
[INFO] [2017-08-03 02:57:28] Epoch 0. Worker 6 set 10: Sample seen 1000320, train loss 0.692525, average computation time 10.262
[INFO] [2017-08-03 02:57:28] Epoch 0. Worker 3 set 9: Sample seen 900288, train loss 0.692525, average computation time 10.334
[INFO] [2017-08-03 02:57:28] Epoch 0. Worker 1 set 10: Sample seen 1000320, train loss 0.692525, average computation time 10.301
[INFO] [2017-08-03 02:57:28] Epoch 0. Worker 0 set 10: Sample seen 1000320, train loss 0.692525, average computation time 10.274
[INFO] [2017-08-03 02:57:29] Epoch 0. Worker 5 set 10: Sample seen 1000320, train loss 0.692525, average computation time 10.249
[INFO] [2017-08-03 02:57:29] Epoch 0. Worker 3 set 10: Sample seen 1000320, train loss 0.692525, average computation time 10.327
[INFO] [2017-08-03 02:57:29] Epoch 0. Worker 2 set 10: Sample seen 1000320, train loss 0.692525, average computation time 10.277
[INFO] [2017-08-03 02:57:30] Epoch 0. Worker 1 set 11: Sample seen 1100352, train loss 0.692525, average computation time 10.330
[INFO] [2017-08-03 02:57:29] Epoch 0. Worker 6 set 11: Sample seen 1100352, train loss 0.692525, average computation time 10.262
[INFO] [2017-08-03 02:57:30] Epoch 0. Worker 0 set 11: Sample seen 1100352, train loss 0.692525, average computation time 10.280
[INFO] [2017-08-03 02:57:30] Epoch 0. Worker 4 set 10: Sample seen 1000320, train loss 0.692525, average computation time 10.286
[INFO] [2017-08-03 02:57:30] Epoch 0. Worker 5 set 11: Sample seen 1100352, train loss 0.692525, average computation time 10.249
[INFO] [2017-08-03 02:57:30] Epoch 0. Worker 7 set 10: Sample seen 1000320, train loss 0.692525, average computation time 10.265
[INFO] [2017-08-03 02:57:30] Epoch 0. Worker 3 set 11: Sample seen 1100352, train loss 0.692525, average computation time 10.321
[INFO] [2017-08-03 02:57:30] Epoch 0. Worker 2 set 11: Sample seen 1100352, train loss 0.692525, average computation time 10.277
[INFO] [2017-08-03 02:57:30] Epoch 0. Worker 4 set 11: Sample seen 1100352, train loss 0.692525, average computation time 10.286
[INFO] [2017-08-03 02:57:30] Epoch 0. Worker 6 set 12: Sample seen 1200384, train loss 0.692525, average computation time 10.262
[INFO] [2017-08-03 02:57:31] Epoch 0. Worker 0 set 12: Sample seen 1200384, train loss 0.692525, average computation time 10.278
[INFO] [2017-08-03 02:57:30] Epoch 0. Worker 7 set 11: Sample seen 1100352, train loss 0.692525, average computation time 10.265
[INFO] [2017-08-03 02:57:30] Epoch 0. Worker 1 set 12: Sample seen 1200384, train loss 0.692525, average computation time 10.324
[INFO] [2017-08-03 02:57:31] Epoch 0. Worker 5 set 12: Sample seen 1200384, train loss 0.692525, average computation time 10.249
[INFO] [2017-08-03 02:57:31] Epoch 0. Worker 3 set 12: Sample seen 1200384, train loss 0.692525, average computation time 10.317
[INFO] [2017-08-03 02:57:32] Epoch 0. Worker 7 set 12: Sample seen 1200384, train loss 0.692525, average computation time 10.265
[INFO] [2017-08-03 02:57:32] Epoch 0. Worker 4 set 12: Sample seen 1200384, train loss 0.692525, average computation time 10.287
[INFO] [2017-08-03 02:57:32] Epoch 0. Worker 2 set 12: Sample seen 1200384, train loss 0.692525, average computation time 10.278
[INFO] [2017-08-03 02:57:33] Epoch 0. Worker 1 set 13: Sample seen 1300416, train loss 0.588704, average computation time 10.321
[INFO] [2017-08-03 02:57:34] Epoch 0. Worker 0 set 13: Sample seen 1300416, train loss 0.589559, average computation time 10.277
[INFO] [2017-08-03 02:57:34] Epoch 0. Worker 6 set 13: Sample seen 1300416, train loss 0.590495, average computation time 10.263
[INFO] [2017-08-03 02:57:34] Epoch 0. Worker 5 set 13: Sample seen 1300416, train loss 0.588221, average computation time 10.250
[INFO] [2017-08-03 02:57:35] Epoch 0. Worker 1 set 14: Sample seen 1400448, train loss 0.184198, average computation time 10.347
[INFO] [2017-08-03 02:57:34] Epoch 0. Worker 7 set 13: Sample seen 1300416, train loss 0.589769, average computation time 10.266
[INFO] [2017-08-03 02:57:34] Epoch 0. Worker 4 set 13: Sample seen 1300416, train loss 0.589660, average computation time 10.288
[INFO] [2017-08-03 02:57:35] Epoch 0. Worker 0 set 14: Sample seen 1400448, train loss 0.183730, average computation time 10.280
[INFO] [2017-08-03 02:57:35] Epoch 0. Worker 6 set 14: Sample seen 1400448, train loss 0.184999, average computation time 10.296
[INFO] [2017-08-03 02:57:35] Epoch 0. Worker 5 set 14: Sample seen 1400448, train loss 0.183105, average computation time 10.254
[INFO] [2017-08-03 02:57:35] Epoch 0. Worker 2 set 13: Sample seen 1300416, train loss 0.589625, average computation time 10.279
[INFO] [2017-08-03 02:57:35] Epoch 0. Worker 3 set 13: Sample seen 1300416, train loss 0.587759, average computation time 10.314
[INFO] [2017-08-03 02:57:35] Epoch 0. Worker 7 set 14: Sample seen 1400448, train loss 0.184956, average computation time 10.271
[INFO] [2017-08-03 02:57:35] Epoch 0. Worker 4 set 14: Sample seen 1400448, train loss 0.186831, average computation time 10.291
[INFO] [2017-08-03 02:57:35] Epoch 0. Worker 2 set 14: Sample seen 1400448, train loss 0.185926, average computation time 10.283
[INFO] [2017-08-03 02:57:35] Epoch 0. Worker 1 set 15: Sample seen 1500480, train loss 0.183556, average computation time 10.346
[INFO] [2017-08-03 02:57:35] Epoch 0. Worker 6 set 15: Sample seen 1500480, train loss 0.186057, average computation time 10.298
[INFO] [2017-08-03 02:57:35] Epoch 0. Worker 3 set 14: Sample seen 1400448, train loss 0.186983, average computation time 10.321
[INFO] [2017-08-03 02:57:36] Epoch 0. Worker 5 set 15: Sample seen 1500480, train loss 0.185517, average computation time 10.258
[INFO] [2017-08-03 02:57:36] Epoch 0. Worker 0 set 15: Sample seen 1500480, train loss 0.184172, average computation time 10.283
[INFO] [2017-08-03 02:57:36] Epoch 0. Worker 4 set 15: Sample seen 1500480, train loss 0.188113, average computation time 10.294
[INFO] [2017-08-03 02:57:36] Epoch 0. Worker 7 set 15: Sample seen 1500480, train loss 0.187496, average computation time 10.279
[INFO] [2017-08-03 02:57:36] Epoch 0. Worker 1 set 16: Sample seen 1600512, train loss 0.185625, average computation time 10.345
[INFO] [2017-08-03 02:57:36] Epoch 0. Worker 2 set 15: Sample seen 1500480, train loss 0.186408, average computation time 10.285
[INFO] [2017-08-03 02:57:36] Epoch 0. Worker 3 set 15: Sample seen 1500480, train loss 0.184946, average computation time 10.323
[INFO] [2017-08-03 02:57:37] Epoch 0. Worker 0 set 16: Sample seen 1600512, train loss 0.184867, average computation time 10.286
[INFO] [2017-08-03 02:57:36] Epoch 0. Worker 6 set 16: Sample seen 1600512, train loss 0.182906, average computation time 10.300
[INFO] [2017-08-03 02:57:37] Epoch 0. Worker 5 set 16: Sample seen 1600512, train loss 0.185439, average computation time 10.262
[INFO] [2017-08-03 02:57:37] Epoch 0. Worker 4 set 16: Sample seen 1600512, train loss 0.184165, average computation time 10.295
[INFO] [2017-08-03 02:57:37] Epoch 0. Worker 7 set 16: Sample seen 1600512, train loss 0.182929, average computation time 10.282
[INFO] [2017-08-03 02:57:37] Epoch 0. Worker 6 set 17: Sample seen 1700544, train loss 0.183111, average computation time 10.302
[INFO] [2017-08-03 02:57:37] Epoch 0. Worker 3 set 16: Sample seen 1600512, train loss 0.186247, average computation time 10.324
[INFO] [2017-08-03 02:57:37] Epoch 0. Worker 1 set 17: Sample seen 1700544, train loss 0.183519, average computation time 10.345
[INFO] [2017-08-03 02:57:38] Epoch 0. Worker 0 set 17: Sample seen 1700544, train loss 0.184928, average computation time 10.288
[INFO] [2017-08-03 02:57:38] Epoch 0. Worker 5 set 17: Sample seen 1700544, train loss 0.184547, average computation time 10.266
[INFO] [2017-08-03 02:57:38] Epoch 0. Worker 2 set 16: Sample seen 1600512, train loss 0.188174, average computation time 10.295
[INFO] [2017-08-03 02:57:38] Epoch 0. Worker 4 set 17: Sample seen 1700544, train loss 0.186816, average computation time 10.296
[INFO] [2017-08-03 02:57:38] Epoch 0. Worker 7 set 17: Sample seen 1700544, train loss 0.185160, average computation time 10.286
[INFO] [2017-08-03 02:57:38] Epoch 0. Worker 6 set 18: Sample seen 1800576, train loss 0.185656, average computation time 10.303
[INFO] [2017-08-03 02:57:38] Epoch 0. Worker 1 set 18: Sample seen 1800576, train loss 0.187335, average computation time 10.345
[INFO] [2017-08-03 02:57:39] Epoch 0. Worker 5 set 18: Sample seen 1800576, train loss 0.185626, average computation time 10.269
[INFO] [2017-08-03 02:57:39] Epoch 0. Worker 3 set 17: Sample seen 1700544, train loss 0.184371, average computation time 10.329
[INFO] [2017-08-03 02:57:39] Epoch 0. Worker 2 set 17: Sample seen 1700544, train loss 0.182421, average computation time 10.298
[INFO] [2017-08-03 02:57:39] Epoch 0. Worker 0 set 18: Sample seen 1800576, train loss 0.186356, average computation time 10.290
[INFO] [2017-08-03 02:57:39] Epoch 0. Worker 4 set 18: Sample seen 1800576, train loss 0.185975, average computation time 10.297
[INFO] [2017-08-03 02:57:40] Epoch 0. Worker 1 set 19: Sample seen 1900608, train loss 0.184331, average computation time 10.345
[INFO] [2017-08-03 02:57:40] Epoch 0. Worker 3 set 18: Sample seen 1800576, train loss 0.185329, average computation time 10.333
[INFO] [2017-08-03 02:57:40] Epoch 0. Worker 7 set 18: Sample seen 1800576, train loss 0.184228, average computation time 10.290
[INFO] [2017-08-03 02:57:40] Epoch 0. Worker 2 set 18: Sample seen 1800576, train loss 0.185946, average computation time 10.299
[INFO] [2017-08-03 02:57:40] Epoch 0. Worker 5 set 19: Sample seen 1900608, train loss 0.187138, average computation time 10.271
[INFO] [2017-08-03 02:57:40] Epoch 0. Worker 6 set 19: Sample seen 1900608, train loss 0.185663, average computation time 10.305
[INFO] [2017-08-03 02:57:40] Epoch 0. Worker 0 set 19: Sample seen 1900608, train loss 0.184387, average computation time 10.292
[INFO] [2017-08-03 02:57:40] Epoch 0. Worker 4 set 19: Sample seen 1900608, train loss 0.183438, average computation time 10.297
[INFO] [2017-08-03 02:57:41] Epoch 0. Worker 7 set 19: Sample seen 1900608, train loss 0.188613, average computation time 10.292
[INFO] [2017-08-03 02:57:41] Epoch 0. Worker 2 set 19: Sample seen 1900608, train loss 0.183188, average computation time 10.300
[INFO] [2017-08-03 02:57:41] Epoch 0. Worker 3 set 19: Sample seen 1900608, train loss 0.185297, average computation time 10.334
[INFO] [2017-08-03 02:57:43] Epoch 0. Worker 5 set 20: Sample seen 2000640, train loss 0.185839, average computation time 10.274
[INFO] [2017-08-03 02:57:43] Epoch 0. Worker 4 set 20: Sample seen 2000640, train loss 0.185932, average computation time 10.299
[INFO] [2017-08-03 02:57:43] Epoch 0. Worker 0 set 20: Sample seen 2000640, train loss 0.184283, average computation time 10.294
[INFO] [2017-08-03 02:57:43] Epoch 0. Worker 6 set 20: Sample seen 2000640, train loss 0.184153, average computation time 10.306
[INFO] [2017-08-03 02:57:43] Epoch 0. Worker 1 set 20: Sample seen 2000640, train loss 0.186578, average computation time 10.346
[INFO] [2017-08-03 02:57:43] Epoch 0. Worker 2 set 20: Sample seen 2000640, train loss 0.187819, average computation time 10.302
[INFO] [2017-08-03 02:57:44] Epoch 0. Worker 5 set 21: Sample seen 2100672, train loss 0.188023, average computation time 10.281
[INFO] [2017-08-03 02:57:43] Epoch 0. Worker 3 set 20: Sample seen 2000640, train loss 0.185295, average computation time 10.318
[INFO] [2017-08-03 02:57:43] Epoch 0. Worker 4 set 21: Sample seen 2100672, train loss 0.186231, average computation time 10.300
[INFO] [2017-08-03 02:57:43] Epoch 0. Worker 0 set 21: Sample seen 2100672, train loss 0.186637, average computation time 10.295
[INFO] [2017-08-03 02:57:43] Epoch 0. Worker 7 set 20: Sample seen 2000640, train loss 0.184531, average computation time 10.295
[INFO] [2017-08-03 02:57:44] Epoch 0. Worker 6 set 21: Sample seen 2100672, train loss 0.186066, average computation time 10.307
[INFO] [2017-08-03 02:57:44] Epoch 0. Worker 2 set 21: Sample seen 2100672, train loss 0.186415, average computation time 10.303
[INFO] [2017-08-03 02:57:44] Epoch 0. Worker 3 set 21: Sample seen 2100672, train loss 0.185287, average computation time 10.320
[INFO] [2017-08-03 02:57:44] Epoch 0. Worker 7 set 21: Sample seen 2100672, train loss 0.185425, average computation time 10.297
[INFO] [2017-08-03 02:57:44] Epoch 0. Worker 4 set 22: Sample seen 2200704, train loss 0.183871, average computation time 10.302
[INFO] [2017-08-03 02:57:45] Epoch 0. Worker 5 set 22: Sample seen 2200704, train loss 0.183826, average computation time 10.283
[INFO] [2017-08-03 02:57:45] Epoch 0. Worker 0 set 22: Sample seen 2200704, train loss 0.186593, average computation time 10.299
[INFO] [2017-08-03 02:57:45] Epoch 0. Worker 1 set 21: Sample seen 2100672, train loss 0.185195, average computation time 10.328
[INFO] [2017-08-03 02:57:45] Epoch 0. Worker 2 set 22: Sample seen 2200704, train loss 0.184650, average computation time 10.303
[INFO] [2017-08-03 02:57:45] Epoch 0. Worker 3 set 22: Sample seen 2200704, train loss 0.184239, average computation time 10.322
[INFO] [2017-08-03 02:57:45] Epoch 0. Worker 7 set 22: Sample seen 2200704, train loss 0.186219, average computation time 10.299
[INFO] [2017-08-03 02:57:45] Epoch 0. Worker 4 set 23: Sample seen 2300736, train loss 0.186504, average computation time 10.302
[INFO] [2017-08-03 02:57:45] Epoch 0. Worker 1 set 22: Sample seen 2200704, train loss 0.184198, average computation time 10.329
[INFO] [2017-08-03 02:57:46] Epoch 0. Worker 0 set 23: Sample seen 2300736, train loss 0.185317, average computation time 10.300
[INFO] [2017-08-03 02:57:46] Epoch 0. Worker 6 set 22: Sample seen 2200704, train loss 0.184102, average computation time 10.308
[INFO] [2017-08-03 02:57:46] Epoch 0. Worker 5 set 23: Sample seen 2300736, train loss 0.183710, average computation time 10.284
[INFO] [2017-08-03 02:57:46] Epoch 0. Worker 2 set 23: Sample seen 2300736, train loss 0.187078, average computation time 10.305
[INFO] [2017-08-03 02:57:46] Epoch 0. Worker 7 set 23: Sample seen 2300736, train loss 0.186892, average computation time 10.303
[INFO] [2017-08-03 02:57:46] Epoch 0. Worker 4 set 24: Sample seen 2400768, train loss 0.185439, average computation time 10.304
[INFO] [2017-08-03 02:57:46] Epoch 0. Worker 1 set 23: Sample seen 2300736, train loss 0.185453, average computation time 10.329
[INFO] [2017-08-03 02:57:46] Epoch 0. Worker 6 set 23: Sample seen 2300736, train loss 0.181418, average computation time 10.309
[INFO] [2017-08-03 02:57:47] Epoch 0. Worker 0 set 24: Sample seen 2400768, train loss 0.185939, average computation time 10.301
[INFO] [2017-08-03 02:57:47] Epoch 0. Worker 3 set 23: Sample seen 2300736, train loss 0.186199, average computation time 10.330
[INFO] [2017-08-03 02:57:47] Epoch 0. Worker 5 set 24: Sample seen 2400768, train loss 0.186979, average computation time 10.285
[INFO] [2017-08-03 02:57:47] Epoch 0. Worker 6 set 24: Sample seen 2400768, train loss 0.182899, average computation time 10.311
