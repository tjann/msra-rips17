[INFO] [2017-08-04 06:10:23] updater type sgd
[INFO] [2017-08-04 06:10:23] Objective type softmax
[INFO] [2017-08-04 06:10:23] Regular type L2
[INFO] [2017-08-04 06:10:23] Init local model, size [2, 54686453]
[INFO] [2017-08-04 06:10:23] updater type sgd
[INFO] [2017-08-04 06:10:23] Objective type softmax
[INFO] [2017-08-04 06:10:23] Regular type L2
[INFO] [2017-08-04 06:10:23] Init local model, size [2, 54686453]
[INFO] [2017-08-04 06:10:23] updater type sgd
[INFO] [2017-08-04 06:10:23] Objective type softmax
[INFO] [2017-08-04 06:10:23] Regular type L2
[INFO] [2017-08-04 06:10:23] Init local model, size [2, 54686453]
[INFO] [2017-08-04 06:10:23] updater type sgd
[INFO] [2017-08-04 06:10:23] Objective type softmax
[INFO] [2017-08-04 06:10:23] Regular type L2
[INFO] [2017-08-04 06:10:23] Init local model, size [2, 54686453]
[INFO] [2017-08-04 06:10:24] updater type sgd
[INFO] [2017-08-04 06:10:24] Objective type softmax
[INFO] [2017-08-04 06:10:24] Regular type L2
[INFO] [2017-08-04 06:10:24] Init local model, size [2, 54686453]
--------------------------------------------------------------------------
[[6388,1],0]: A high-performance Open MPI point-to-point messaging module
was unable to find any relevant network interfaces:

Module: OpenFabrics (openib)
  Host: multiversohkcpu01

Another transport will be used instead, although this may result in
lower performance.
--------------------------------------------------------------------------
[INFO] [2017-08-04 06:10:23] updater type sgd
[INFO] [2017-08-04 06:10:23] Objective type softmax
[INFO] [2017-08-04 06:10:23] Regular type L2
[INFO] [2017-08-04 06:10:23] Init local model, size [2, 54686453]
[INFO] [2017-08-04 06:10:23] updater type sgd
[INFO] [2017-08-04 06:10:23] Objective type softmax
[INFO] [2017-08-04 06:10:23] Regular type L2
[INFO] [2017-08-04 06:10:23] Init local model, size [2, 54686453]
[INFO] [2017-08-04 06:10:23] updater type sgd
[INFO] [2017-08-04 06:10:23] Objective type softmax
[INFO] [2017-08-04 06:10:23] Regular type L2
[INFO] [2017-08-04 06:10:23] Init local model, size [2, 54686453]
--------------------------------------------------------------------------
[[6388,1],2]: A high-performance Open MPI point-to-point messaging module
was unable to find any relevant network interfaces:

Module: OpenFabrics (openib)
  Host: multiversohkcpu03

Another transport will be used instead, although this may result in
lower performance.
--------------------------------------------------------------------------
[INFO] [2017-08-04 06:10:23] multiverso MPI-Net is initialized under MPI_THREAD_SERIALIZED mode.
[INFO] [2017-08-04 06:10:23] multiverso MPI-Net is initialized under MPI_THREAD_SERIALIZED mode.
[INFO] [2017-08-04 06:10:24] multiverso MPI-Net is initialized under MPI_THREAD_SERIALIZED mode.
[INFO] [2017-08-04 06:10:23] multiverso MPI-Net is initialized under MPI_THREAD_SERIALIZED mode.
[INFO] [2017-08-04 06:10:23] multiverso MPI-Net is initialized under MPI_THREAD_SERIALIZED mode.
[INFO] [2017-08-04 06:10:23] multiverso MPI-Net is initialized under MPI_THREAD_SERIALIZED mode.
[INFO] [2017-08-04 06:10:23] multiverso MPI-Net is initialized under MPI_THREAD_SERIALIZED mode.
[INFO] [2017-08-04 06:10:23] multiverso MPI-Net is initialized under MPI_THREAD_SERIALIZED mode.
[INFO] [2017-08-04 06:10:23] All nodes registered. System contains 8 nodes. num_worker = 8, num_server = 8
[INFO] [2017-08-04 06:10:23] Create a sync server
[INFO] [2017-08-04 06:10:23] Create a sync server
[INFO] [2017-08-04 06:10:23] Create a sync server
[INFO] [2017-08-04 06:10:23] Create a sync server
[INFO] [2017-08-04 06:10:24] Create a sync server
[INFO] [2017-08-04 06:10:23] Create a sync server
[INFO] [2017-08-04 06:10:23] Create a sync server
[INFO] [2017-08-04 06:10:23] Create a sync server
[INFO] [2017-08-04 06:10:23] Rank 0: Multiverso start successfully
[INFO] [2017-08-04 06:10:23] Rank 4: Multiverso start successfully
[INFO] [2017-08-04 06:10:24] Rank 1: Multiverso start successfully
[INFO] [2017-08-04 06:10:23] Rank 6: Multiverso start successfully
[INFO] [2017-08-04 06:10:23] Rank 2: Multiverso start successfully
[INFO] [2017-08-04 06:10:23] Rank 5: Multiverso start successfully
[INFO] [2017-08-04 06:10:23] Rank 3: Multiverso start successfully
[INFO] [2017-08-04 06:10:23] Rank 7: Multiverso start successfully
[INFO] [2017-08-04 06:10:23] SparseServer 6 create table with 13671613 elements,       offset 82029678
[INFO] [2017-08-04 06:10:23] SparseWorker 6 create SparseTable with 109372906 elements
[INFO] [2017-08-04 06:10:23] SparseServer 7 create table with 13671615 elements,       offset 95701291
[INFO] [2017-08-04 06:10:23] SparseWorker 7 create SparseTable with 109372906 elements
[INFO] [2017-08-04 06:10:24] SparseServer 1 create table with 13671613 elements,       offset 13671613
[INFO] [2017-08-04 06:10:24] SparseWorker 1 create SparseTable with 109372906 elements
[INFO] [2017-08-04 06:10:24] SparseServer 2 create table with 13671613 elements,       offset 27343226
[INFO] [2017-08-04 06:10:24] SparseWorker 2 create SparseTable with 109372906 elements
[INFO] [2017-08-04 06:10:23] SparseServer 0 create table with 13671613 elements,       offset 0
[INFO] [2017-08-04 06:10:23] SparseServer 5 create table with 13671613 elements,       offset 68358065
[INFO] [2017-08-04 06:10:23] SparseWorker 0 create SparseTable with 109372906 elements
[INFO] [2017-08-04 06:10:23] SparseWorker 5 create SparseTable with 109372906 elements
[INFO] [2017-08-04 06:10:23] SparseServer 4 create table with 13671613 elements,       offset 54686452
[INFO] [2017-08-04 06:10:23] SparseWorker 4 create SparseTable with 109372906 elements
[INFO] [2017-08-04 06:10:23] Init ps model, size [2, 54686453]
[INFO] [2017-08-04 06:10:23] ps model with sync frequency 1000
[INFO] [2017-08-04 06:10:23] Train with file /home/hkust/rips/divkdd12.tr
[INFO] [2017-08-04 06:10:23] SparseServer 3 create table with 13671613 elements,       offset 41014839
[INFO] [2017-08-04 06:10:23] SparseWorker 3 create SparseTable with 109372906 elements
[INFO] [2017-08-04 06:10:23] Init ps model, size [2, 54686453]
[INFO] [2017-08-04 06:10:23] ps model with sync frequency 1000
[INFO] [2017-08-04 06:10:23] Train with file /home/hkust/rips/divkdd12.tr
[INFO] [2017-08-04 06:10:23] Init ps model, size [2, 54686453]
[INFO] [2017-08-04 06:10:23] ps model with sync frequency 1000
[INFO] [2017-08-04 06:10:23] Train with file /home/hkust/rips/divkdd12.tr
[INFO] [2017-08-04 06:10:24] Init ps model, size [2, 54686453]
[INFO] [2017-08-04 06:10:24] ps model with sync frequency 1000
[INFO] [2017-08-04 06:10:24] Train with file /home/hkust/rips/divkdd12.tr
[INFO] [2017-08-04 06:10:23] Init ps model, size [2, 54686453]
[INFO] [2017-08-04 06:10:23] ps model with sync frequency 1000
[INFO] [2017-08-04 06:10:23] Train with file /home/hkust/rips/divkdd12.tr
[INFO] [2017-08-04 06:10:23] Init ps model, size [2, 54686453]
[INFO] [2017-08-04 06:10:23] ps model with sync frequency 1000
[INFO] [2017-08-04 06:10:23] Train with file /home/hkust/rips/divkdd12.tr
[INFO] [2017-08-04 06:10:23] Init ps model, size [2, 54686453]
[INFO] [2017-08-04 06:10:23] ps model with sync frequency 1000
[INFO] [2017-08-04 06:10:23] Train with file /home/hkust/rips/divkdd12.tr
[INFO] [2017-08-04 06:10:24] Init ps model, size [2, 54686453]
[INFO] [2017-08-04 06:10:24] ps model with sync frequency 1000
[INFO] [2017-08-04 06:10:24] Train with file /home/hkust/rips/divkdd12.tr
[INFO] [2017-08-04 06:10:38] Epoch 0. Worker 6 set 1: Sample seen 1004800, train loss 0.297923, average computation time 10.330
[INFO] [2017-08-04 06:10:38] Epoch 0. Worker 5 set 1: Sample seen 1004800, train loss 0.298321, average computation time 10.323
[INFO] [2017-08-04 06:10:38] Epoch 0. Worker 4 set 1: Sample seen 1004800, train loss 0.298607, average computation time 10.268
[INFO] [2017-08-04 06:10:38] Epoch 0. Worker 0 set 1: Sample seen 1004800, train loss 0.298343, average computation time 10.280
[INFO] [2017-08-04 06:10:39] Epoch 0. Worker 1 set 1: Sample seen 1004800, train loss 0.298471, average computation time 10.313
[INFO] [2017-08-04 06:10:39] Epoch 0. Worker 7 set 1: Sample seen 1004800, train loss 0.298727, average computation time 10.350
[INFO] [2017-08-04 06:10:39] Epoch 0. Worker 2 set 1: Sample seen 1004800, train loss 0.298295, average computation time 10.350
[INFO] [2017-08-04 06:10:39] Epoch 0. Worker 3 set 1: Sample seen 1004800, train loss 0.298341, average computation time 10.370
[INFO] [2017-08-04 06:10:54] Epoch 0. Worker 6 set 2: Sample seen 2009600, train loss 0.234766, average computation time 10.333
[INFO] [2017-08-04 06:10:54] Epoch 0. Worker 1 set 2: Sample seen 2009600, train loss 0.234432, average computation time 10.322
[INFO] [2017-08-04 06:10:54] Epoch 0. Worker 4 set 2: Sample seen 2009600, train loss 0.234201, average computation time 10.295
[INFO] [2017-08-04 06:10:54] Epoch 0. Worker 0 set 2: Sample seen 2009600, train loss 0.234631, average computation time 10.300
[INFO] [2017-08-04 06:10:53] Epoch 0. Worker 5 set 2: Sample seen 2009600, train loss 0.234992, average computation time 10.315
[INFO] [2017-08-04 06:10:54] Epoch 0. Worker 2 set 2: Sample seen 2009600, train loss 0.235289, average computation time 10.346
[INFO] [2017-08-04 06:10:54] Epoch 0. Worker 7 set 2: Sample seen 2009600, train loss 0.234932, average computation time 10.348
[INFO] [2017-08-04 06:10:54] Epoch 0. Worker 3 set 2: Sample seen 2009600, train loss 0.235190, average computation time 10.378
[INFO] [2017-08-04 06:11:09] Epoch 0. Worker 4 set 3: Sample seen 3014400, train loss 0.234628, average computation time 10.305
[INFO] [2017-08-04 06:11:09] Epoch 0. Worker 5 set 3: Sample seen 3014400, train loss 0.235194, average computation time 10.319
[INFO] [2017-08-04 06:11:09] Epoch 0. Worker 6 set 3: Sample seen 3014400, train loss 0.234881, average computation time 10.335
[INFO] [2017-08-04 06:11:10] Epoch 0. Worker 2 set 3: Sample seen 3014400, train loss 0.234875, average computation time 10.343
[INFO] [2017-08-04 06:11:09] Epoch 0. Worker 0 set 3: Sample seen 3014400, train loss 0.234552, average computation time 10.309
[INFO] [2017-08-04 06:11:10] Epoch 0. Worker 1 set 3: Sample seen 3014400, train loss 0.234646, average computation time 10.321
[INFO] [2017-08-04 06:11:10] Epoch 0. Worker 7 set 3: Sample seen 3014400, train loss 0.234893, average computation time 10.346
[INFO] [2017-08-04 06:11:10] Epoch 0. Worker 3 set 3: Sample seen 3014400, train loss 0.234729, average computation time 10.360
[INFO] [2017-08-04 06:11:25] Epoch 0. Worker 5 set 4: Sample seen 4019200, train loss 0.235337, average computation time 10.325
[INFO] [2017-08-04 06:11:25] Epoch 0. Worker 4 set 4: Sample seen 4019200, train loss 0.235238, average computation time 10.298
[INFO] [2017-08-04 06:11:25] Epoch 0. Worker 2 set 4: Sample seen 4019200, train loss 0.235134, average computation time 10.337
[INFO] [2017-08-04 06:11:25] Epoch 0. Worker 6 set 4: Sample seen 4019200, train loss 0.234927, average computation time 10.337
[INFO] [2017-08-04 06:11:25] Epoch 0. Worker 7 set 4: Sample seen 4019200, train loss 0.234470, average computation time 10.349
[INFO] [2017-08-04 06:11:25] Epoch 0. Worker 1 set 4: Sample seen 4019200, train loss 0.234081, average computation time 10.320
[INFO] [2017-08-04 06:11:25] Epoch 0. Worker 0 set 4: Sample seen 4019200, train loss 0.234536, average computation time 10.324
[INFO] [2017-08-04 06:11:25] Epoch 0. Worker 3 set 4: Sample seen 4019200, train loss 0.235089, average computation time 10.353
[INFO] [2017-08-04 06:11:40] Epoch 0. Worker 4 set 5: Sample seen 5024000, train loss 0.235503, average computation time 10.294
[INFO] [2017-08-04 06:11:40] Epoch 0. Worker 0 set 5: Sample seen 5024000, train loss 0.234844, average computation time 10.318
[INFO] [2017-08-04 06:11:40] Epoch 0. Worker 1 set 5: Sample seen 5024000, train loss 0.235698, average computation time 10.320
[INFO] [2017-08-04 06:11:40] Epoch 0. Worker 5 set 5: Sample seen 5024000, train loss 0.234878, average computation time 10.326
[INFO] [2017-08-04 06:11:40] Epoch 0. Worker 6 set 5: Sample seen 5024000, train loss 0.234332, average computation time 10.336
[INFO] [2017-08-04 06:11:40] Epoch 0. Worker 2 set 5: Sample seen 5024000, train loss 0.234316, average computation time 10.336
[INFO] [2017-08-04 06:11:40] Epoch 0. Worker 7 set 5: Sample seen 5024000, train loss 0.235088, average computation time 10.351
[INFO] [2017-08-04 06:11:40] Epoch 0. Worker 3 set 5: Sample seen 5024000, train loss 0.235161, average computation time 10.358
[INFO] [2017-08-04 06:11:55] Epoch 0. Worker 5 set 6: Sample seen 6028800, train loss 0.234907, average computation time 10.326
[INFO] [2017-08-04 06:11:56] Epoch 0. Worker 4 set 6: Sample seen 6028800, train loss 0.235240, average computation time 10.306
[INFO] [2017-08-04 06:11:56] Epoch 0. Worker 0 set 6: Sample seen 6028800, train loss 0.234646, average computation time 10.307
[INFO] [2017-08-04 06:11:56] Epoch 0. Worker 6 set 6: Sample seen 6028800, train loss 0.235244, average computation time 10.336
[INFO] [2017-08-04 06:11:56] Epoch 0. Worker 1 set 6: Sample seen 6028800, train loss 0.234340, average computation time 10.322
[INFO] [2017-08-04 06:11:56] Epoch 0. Worker 2 set 6: Sample seen 6028800, train loss 0.234291, average computation time 10.337
[INFO] [2017-08-04 06:11:56] Epoch 0. Worker 7 set 6: Sample seen 6028800, train loss 0.234625, average computation time 10.349
[INFO] [2017-08-04 06:11:56] Epoch 0. Worker 3 set 6: Sample seen 6028800, train loss 0.234033, average computation time 10.370
[INFO] [2017-08-04 06:12:11] Epoch 0. Worker 4 set 7: Sample seen 7033600, train loss 0.234475, average computation time 10.309
[INFO] [2017-08-04 06:12:10] Epoch 0. Worker 5 set 7: Sample seen 7033600, train loss 0.235135, average computation time 10.324
[INFO] [2017-08-04 06:12:11] Epoch 0. Worker 1 set 7: Sample seen 7033600, train loss 0.234607, average computation time 10.322
[INFO] [2017-08-04 06:12:11] Epoch 0. Worker 6 set 7: Sample seen 7033600, train loss 0.235012, average computation time 10.336
[INFO] [2017-08-04 06:12:11] Epoch 0. Worker 0 set 7: Sample seen 7033600, train loss 0.234729, average computation time 10.323
[INFO] [2017-08-04 06:12:11] Epoch 0. Worker 7 set 7: Sample seen 7033600, train loss 0.234977, average computation time 10.351
[INFO] [2017-08-04 06:12:11] Epoch 0. Worker 3 set 7: Sample seen 7033600, train loss 0.235165, average computation time 10.362
[INFO] [2017-08-04 06:12:11] Epoch 0. Worker 2 set 7: Sample seen 7033600, train loss 0.234816, average computation time 10.337
[INFO] [2017-08-04 06:12:26] Epoch 0. Worker 4 set 8: Sample seen 8038400, train loss 0.235360, average computation time 10.316
[INFO] [2017-08-04 06:12:26] Epoch 0. Worker 0 set 8: Sample seen 8038400, train loss 0.234677, average computation time 10.323
[INFO] [2017-08-04 06:12:26] Epoch 0. Worker 6 set 8: Sample seen 8038400, train loss 0.234188, average computation time 10.336
[INFO] [2017-08-04 06:12:26] Epoch 0. Worker 5 set 8: Sample seen 8038400, train loss 0.234972, average computation time 10.324
[INFO] [2017-08-04 06:12:27] Epoch 0. Worker 1 set 8: Sample seen 8038400, train loss 0.234513, average computation time 10.322
[INFO] [2017-08-04 06:12:27] Epoch 0. Worker 7 set 8: Sample seen 8038400, train loss 0.234912, average computation time 10.352
[INFO] [2017-08-04 06:12:27] Epoch 0. Worker 3 set 8: Sample seen 8038400, train loss 0.234458, average computation time 10.356
[INFO] [2017-08-04 06:12:27] Epoch 0. Worker 2 set 8: Sample seen 8038400, train loss 0.235610, average computation time 10.335
[INFO] [2017-08-04 06:12:42] Epoch 0. Worker 5 set 9: Sample seen 9043200, train loss 0.235118, average computation time 10.324
[INFO] [2017-08-04 06:12:42] Epoch 0. Worker 4 set 9: Sample seen 9043200, train loss 0.234668, average computation time 10.317
[INFO] [2017-08-04 06:12:42] Epoch 0. Worker 0 set 9: Sample seen 9043200, train loss 0.234960, average computation time 10.327
[INFO] [2017-08-04 06:12:42] Epoch 0. Worker 1 set 9: Sample seen 9043200, train loss 0.234924, average computation time 10.321
[INFO] [2017-08-04 06:12:42] Epoch 0. Worker 6 set 9: Sample seen 9043200, train loss 0.235150, average computation time 10.336
[INFO] [2017-08-04 06:12:42] Epoch 0. Worker 7 set 9: Sample seen 9043200, train loss 0.234983, average computation time 10.353
[INFO] [2017-08-04 06:12:42] Epoch 0. Worker 2 set 9: Sample seen 9043200, train loss 0.234973, average computation time 10.334
[INFO] [2017-08-04 06:12:42] Epoch 0. Worker 3 set 9: Sample seen 9043200, train loss 0.234449, average computation time 10.344
[INFO] [2017-08-04 06:12:58] Epoch 0. Worker 0 set 10: Sample seen 10048000, train loss 0.234473, average computation time 10.319
[INFO] [2017-08-04 06:12:58] Epoch 0. Worker 5 set 10: Sample seen 10048000, train loss 0.234761, average computation time 10.324
[INFO] [2017-08-04 06:12:58] Epoch 0. Worker 4 set 10: Sample seen 10048000, train loss 0.234639, average computation time 10.304
[INFO] [2017-08-04 06:12:58] Epoch 0. Worker 1 set 10: Sample seen 10048000, train loss 0.235272, average computation time 10.320
[INFO] [2017-08-04 06:12:58] Epoch 0. Worker 6 set 10: Sample seen 10048000, train loss 0.234871, average computation time 10.336
[INFO] [2017-08-04 06:12:58] Epoch 0. Worker 7 set 10: Sample seen 10048000, train loss 0.234816, average computation time 10.353
[INFO] [2017-08-04 06:12:59] Epoch 0. Worker 2 set 10: Sample seen 10048000, train loss 0.234554, average computation time 10.334
[INFO] [2017-08-04 06:12:58] Epoch 0. Worker 3 set 10: Sample seen 10048000, train loss 0.234542, average computation time 10.355
[INFO] [2017-08-04 06:13:13] Epoch 0. Worker 4 set 11: Sample seen 11052800, train loss 0.235447, average computation time 10.306
[INFO] [2017-08-04 06:13:13] Epoch 0. Worker 6 set 11: Sample seen 11052800, train loss 0.234600, average computation time 10.335
[INFO] [2017-08-04 06:13:13] Epoch 0. Worker 5 set 11: Sample seen 11052800, train loss 0.235080, average computation time 10.324
[INFO] [2017-08-04 06:13:13] Epoch 0. Worker 0 set 11: Sample seen 11052800, train loss 0.235449, average computation time 10.319
[INFO] [2017-08-04 06:13:13] Epoch 0. Worker 7 set 11: Sample seen 11052800, train loss 0.235073, average computation time 10.352
[INFO] [2017-08-04 06:13:13] Epoch 0. Worker 1 set 11: Sample seen 11052800, train loss 0.234860, average computation time 10.322
[INFO] [2017-08-04 06:13:14] Epoch 0. Worker 2 set 11: Sample seen 11052800, train loss 0.234304, average computation time 10.335
[INFO] [2017-08-04 06:13:13] Epoch 0. Worker 3 set 11: Sample seen 11052800, train loss 0.235211, average computation time 10.357
[INFO] [2017-08-04 06:13:28] Epoch 0. Worker 4 set 12: Sample seen 12057600, train loss 0.234674, average computation time 10.311
[INFO] [2017-08-04 06:13:28] Epoch 0. Worker 6 set 12: Sample seen 12057600, train loss 0.234895, average computation time 10.335
[INFO] [2017-08-04 06:13:28] Epoch 0. Worker 5 set 12: Sample seen 12057600, train loss 0.235286, average computation time 10.324
[INFO] [2017-08-04 06:13:28] Epoch 0. Worker 0 set 12: Sample seen 12057600, train loss 0.234543, average computation time 10.316
[INFO] [2017-08-04 06:13:29] Epoch 0. Worker 7 set 12: Sample seen 12057600, train loss 0.234616, average computation time 10.351
[INFO] [2017-08-04 06:13:29] Epoch 0. Worker 1 set 12: Sample seen 12057600, train loss 0.235058, average computation time 10.323
[INFO] [2017-08-04 06:13:29] Epoch 0. Worker 2 set 12: Sample seen 12057600, train loss 0.234998, average computation time 10.338
[INFO] [2017-08-04 06:13:29] Epoch 0. Worker 3 set 12: Sample seen 12057600, train loss 0.234384, average computation time 10.366
[INFO] [2017-08-04 06:13:44] Epoch 0. Worker 5 set 13: Sample seen 13062400, train loss 0.234679, average computation time 10.324
[INFO] [2017-08-04 06:13:44] Epoch 0. Worker 4 set 13: Sample seen 13062400, train loss 0.234477, average computation time 10.312
[INFO] [2017-08-04 06:13:44] Epoch 0. Worker 0 set 13: Sample seen 13062400, train loss 0.234460, average computation time 10.320
[INFO] [2017-08-04 06:13:44] Epoch 0. Worker 1 set 13: Sample seen 13062400, train loss 0.234865, average computation time 10.322
[INFO] [2017-08-04 06:13:44] Epoch 0. Worker 6 set 13: Sample seen 13062400, train loss 0.234391, average computation time 10.334
[INFO] [2017-08-04 06:13:44] Epoch 0. Worker 2 set 13: Sample seen 13062400, train loss 0.235153, average computation time 10.340
[INFO] [2017-08-04 06:13:44] Epoch 0. Worker 7 set 13: Sample seen 13062400, train loss 0.234519, average computation time 10.350
[INFO] [2017-08-04 06:13:44] Epoch 0. Worker 3 set 13: Sample seen 13062400, train loss 0.234831, average computation time 10.361
[INFO] [2017-08-04 06:13:59] Epoch 0. Worker 4 set 14: Sample seen 14067200, train loss 0.235101, average computation time 10.309
[INFO] [2017-08-04 06:13:59] Epoch 0. Worker 0 set 14: Sample seen 14067200, train loss 0.234598, average computation time 10.326
[INFO] [2017-08-04 06:13:59] Epoch 0. Worker 5 set 14: Sample seen 14067200, train loss 0.234671, average computation time 10.323
[INFO] [2017-08-04 06:14:00] Epoch 0. Worker 1 set 14: Sample seen 14067200, train loss 0.234322, average computation time 10.323
[INFO] [2017-08-04 06:13:59] Epoch 0. Worker 6 set 14: Sample seen 14067200, train loss 0.234363, average computation time 10.334
[INFO] [2017-08-04 06:14:00] Epoch 0. Worker 7 set 14: Sample seen 14067200, train loss 0.234678, average computation time 10.350
[INFO] [2017-08-04 06:14:00] Epoch 0. Worker 2 set 14: Sample seen 14067200, train loss 0.235357, average computation time 10.342
[INFO] [2017-08-04 06:14:00] Epoch 0. Worker 3 set 14: Sample seen 14067200, train loss 0.235421, average computation time 10.365
[INFO] [2017-08-04 06:14:14] Finish train, total sample 14963129
[INFO] [2017-08-04 06:14:13] Finish train, total sample 14963129
[INFO] [2017-08-04 06:14:13] Finish train, total sample 14963129
[INFO] [2017-08-04 06:14:13] Finish train, total sample 14963130
[INFO] [2017-08-04 06:14:13] Finish train, total sample 14963129
[INFO] [2017-08-04 06:14:13] Finish train, total sample 14963129
[INFO] [2017-08-04 06:14:13] Finish train, total sample 14963129
[INFO] [2017-08-04 06:14:14] Finish train, total sample 14963129
[INFO] [2017-08-04 06:14:14] Multiverso Shutdown successfully
[INFO] [2017-08-04 06:14:14] Multiverso Shutdown successfully
[INFO] [2017-08-04 06:14:14] Multiverso Shutdown successfully
[INFO] [2017-08-04 06:14:13] Multiverso Shutdown successfully
[INFO] [2017-08-04 06:14:13] Multiverso Shutdown successfully
[INFO] [2017-08-04 06:14:14] Multiverso Shutdown successfully
[INFO] [2017-08-04 06:14:13] Multiverso Shutdown successfully
[INFO] [2017-08-04 06:14:13] Multiverso Shutdown successfully
