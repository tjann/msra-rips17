[INFO] [2017-08-04 05:47:51] updater type sgd
[INFO] [2017-08-04 05:47:51] Objective type softmax
[INFO] [2017-08-04 05:47:51] Regular type L2
[INFO] [2017-08-04 05:47:51] Init local model, size [2, 54686453]
[INFO] [2017-08-04 05:47:51] updater type sgd
[INFO] [2017-08-04 05:47:51] Objective type softmax
[INFO] [2017-08-04 05:47:51] Regular type L2
[INFO] [2017-08-04 05:47:51] Init local model, size [2, 54686453]
[INFO] [2017-08-04 05:47:51] updater type sgd
[INFO] [2017-08-04 05:47:51] Objective type softmax
[INFO] [2017-08-04 05:47:51] Regular type L2
[INFO] [2017-08-04 05:47:51] Init local model, size [2, 54686453]
[INFO] [2017-08-04 05:47:51] updater type sgd
[INFO] [2017-08-04 05:47:51] Objective type softmax
[INFO] [2017-08-04 05:47:51] Regular type L2
[INFO] [2017-08-04 05:47:51] Init local model, size [2, 54686453]
[INFO] [2017-08-04 05:47:51] updater type sgd
[INFO] [2017-08-04 05:47:51] Objective type softmax
[INFO] [2017-08-04 05:47:51] Regular type L2
[INFO] [2017-08-04 05:47:51] Init local model, size [2, 54686453]
[INFO] [2017-08-04 05:47:51] updater type sgd
[INFO] [2017-08-04 05:47:51] Objective type softmax
[INFO] [2017-08-04 05:47:51] Regular type L2
[INFO] [2017-08-04 05:47:51] Init local model, size [2, 54686453]
[INFO] [2017-08-04 05:47:51] updater type sgd
[INFO] [2017-08-04 05:47:51] Objective type softmax
[INFO] [2017-08-04 05:47:51] Regular type L2
[INFO] [2017-08-04 05:47:51] Init local model, size [2, 54686453]
[INFO] [2017-08-04 05:47:51] updater type sgd
[INFO] [2017-08-04 05:47:51] Objective type softmax
[INFO] [2017-08-04 05:47:51] Regular type L2
[INFO] [2017-08-04 05:47:51] Init local model, size [2, 54686453]
--------------------------------------------------------------------------
[[6831,1],0]: A high-performance Open MPI point-to-point messaging module
was unable to find any relevant network interfaces:

Module: OpenFabrics (openib)
  Host: multiversohkcpu01

Another transport will be used instead, although this may result in
lower performance.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
[[6831,1],2]: A high-performance Open MPI point-to-point messaging module
was unable to find any relevant network interfaces:

Module: OpenFabrics (openib)
  Host: multiversohkcpu03

Another transport will be used instead, although this may result in
lower performance.
--------------------------------------------------------------------------
[INFO] [2017-08-04 05:47:51] multiverso MPI-Net is initialized under MPI_THREAD_SERIALIZED mode.
[INFO] [2017-08-04 05:47:51] multiverso MPI-Net is initialized under MPI_THREAD_SERIALIZED mode.
[INFO] [2017-08-04 05:47:51] multiverso MPI-Net is initialized under MPI_THREAD_SERIALIZED mode.
[INFO] [2017-08-04 05:47:51] multiverso MPI-Net is initialized under MPI_THREAD_SERIALIZED mode.
[INFO] [2017-08-04 05:47:51] multiverso MPI-Net is initialized under MPI_THREAD_SERIALIZED mode.
[INFO] [2017-08-04 05:47:51] multiverso MPI-Net is initialized under MPI_THREAD_SERIALIZED mode.
[INFO] [2017-08-04 05:47:51] multiverso MPI-Net is initialized under MPI_THREAD_SERIALIZED mode.
[INFO] [2017-08-04 05:47:51] multiverso MPI-Net is initialized under MPI_THREAD_SERIALIZED mode.
[INFO] [2017-08-04 05:47:51] All nodes registered. System contains 8 nodes. num_worker = 8, num_server = 8
[INFO] [2017-08-04 05:47:51] Create a sync server
[INFO] [2017-08-04 05:47:51] Create a sync server
[INFO] [2017-08-04 05:47:51] Create a sync server
[INFO] [2017-08-04 05:47:51] Create a sync server
[INFO] [2017-08-04 05:47:51] Create a sync server
[INFO] [2017-08-04 05:47:51] Create a sync server
[INFO] [2017-08-04 05:47:51] Create a sync server
[INFO] [2017-08-04 05:47:51] Create a sync server
[INFO] [2017-08-04 05:47:51] Rank 0: Multiverso start successfully
[INFO] [2017-08-04 05:47:51] Rank 3: Multiverso start successfully
[INFO] [2017-08-04 05:47:51] Rank 2: Multiverso start successfully
[INFO] [2017-08-04 05:47:51] Rank 4: Multiverso start successfully
[INFO] [2017-08-04 05:47:51] Rank 6: Multiverso start successfully
[INFO] [2017-08-04 05:47:51] Rank 1: Multiverso start successfully
[INFO] [2017-08-04 05:47:51] Rank 5: Multiverso start successfully
[INFO] [2017-08-04 05:47:51] Rank 7: Multiverso start successfully
[INFO] [2017-08-04 05:47:51] SparseServer 6 create table with 13671613 elements,       offset 82029678
[INFO] [2017-08-04 05:47:51] SparseWorker 6 create SparseTable with 109372906 elements
[INFO] [2017-08-04 05:47:51] SparseServer 2 create table with 13671613 elements,       offset 27343226
[INFO] [2017-08-04 05:47:51] SparseWorker 2 create SparseTable with 109372906 elements
[INFO] [2017-08-04 05:47:51] SparseServer 0 create table with 13671613 elements,       offset 0
[INFO] [2017-08-04 05:47:51] SparseWorker 0 create SparseTable with 109372906 elements
[INFO] [2017-08-04 05:47:51] SparseServer 5 create table with 13671613 elements,       offset 68358065
[INFO] [2017-08-04 05:47:51] SparseWorker 5 create SparseTable with 109372906 elements
[INFO] [2017-08-04 05:47:51] SparseServer 7 create table with 13671615 elements,       offset 95701291
[INFO] [2017-08-04 05:47:51] SparseWorker 7 create SparseTable with 109372906 elements
[INFO] [2017-08-04 05:47:51] SparseServer 1 create table with 13671613 elements,       offset 13671613
[INFO] [2017-08-04 05:47:51] SparseWorker 1 create SparseTable with 109372906 elements
[INFO] [2017-08-04 05:47:51] SparseServer 3 create table with 13671613 elements,       offset 41014839
[INFO] [2017-08-04 05:47:51] SparseWorker 3 create SparseTable with 109372906 elements
[INFO] [2017-08-04 05:47:51] Init ps model, size [2, 54686453]
[INFO] [2017-08-04 05:47:51] ps model with sync frequency 10000
[INFO] [2017-08-04 05:47:51] Train with file /home/hkust/rips/divkdd12.tr
[INFO] [2017-08-04 05:47:51] SparseServer 4 create table with 13671613 elements,       offset 54686452
[INFO] [2017-08-04 05:47:51] SparseWorker 4 create SparseTable with 109372906 elements
[INFO] [2017-08-04 05:47:51] Init ps model, size [2, 54686453]
[INFO] [2017-08-04 05:47:51] ps model with sync frequency 10000
[INFO] [2017-08-04 05:47:51] Train with file /home/hkust/rips/divkdd12.tr
[INFO] [2017-08-04 05:47:51] Init ps model, size [2, 54686453]
[INFO] [2017-08-04 05:47:51] ps model with sync frequency 10000
[INFO] [2017-08-04 05:47:51] Train with file /home/hkust/rips/divkdd12.tr
[INFO] [2017-08-04 05:47:51] Init ps model, size [2, 54686453]
[INFO] [2017-08-04 05:47:51] ps model with sync frequency 10000
[INFO] [2017-08-04 05:47:51] Train with file /home/hkust/rips/divkdd12.tr
[INFO] [2017-08-04 05:47:51] Init ps model, size [2, 54686453]
[INFO] [2017-08-04 05:47:51] ps model with sync frequency 10000
[INFO] [2017-08-04 05:47:51] Train with file /home/hkust/rips/divkdd12.tr
[INFO] [2017-08-04 05:47:51] Init ps model, size [2, 54686453]
[INFO] [2017-08-04 05:47:51] ps model with sync frequency 10000
[INFO] [2017-08-04 05:47:51] Train with file /home/hkust/rips/divkdd12.tr
[INFO] [2017-08-04 05:47:51] Init ps model, size [2, 54686453]
[INFO] [2017-08-04 05:47:51] ps model with sync frequency 10000
[INFO] [2017-08-04 05:47:51] Train with file /home/hkust/rips/divkdd12.tr
[INFO] [2017-08-04 05:47:51] Init ps model, size [2, 54686453]
[INFO] [2017-08-04 05:47:51] ps model with sync frequency 10000
[INFO] [2017-08-04 05:47:51] Train with file /home/hkust/rips/divkdd12.tr
[INFO] [2017-08-04 05:48:02] Epoch 0. Worker 4 set 1: Sample seen 1004800, train loss 0.693223, average computation time 10.252
[INFO] [2017-08-04 05:48:02] Epoch 0. Worker 5 set 1: Sample seen 1004800, train loss 0.693223, average computation time 10.210
[INFO] [2017-08-04 05:48:02] Epoch 0. Worker 0 set 1: Sample seen 1004800, train loss 0.693223, average computation time 10.255
[INFO] [2017-08-04 05:48:02] Epoch 0. Worker 2 set 1: Sample seen 1004800, train loss 0.693223, average computation time 10.269
[INFO] [2017-08-04 05:48:03] Epoch 0. Worker 7 set 1: Sample seen 1004800, train loss 0.693223, average computation time 10.310
[INFO] [2017-08-04 05:48:02] Epoch 0. Worker 6 set 1: Sample seen 1004800, train loss 0.693223, average computation time 10.231
[INFO] [2017-08-04 05:48:03] Epoch 0. Worker 3 set 1: Sample seen 1004800, train loss 0.693223, average computation time 10.282
[INFO] [2017-08-04 05:48:03] Epoch 0. Worker 1 set 1: Sample seen 1004800, train loss 0.693223, average computation time 10.295
[INFO] [2017-08-04 05:48:17] Epoch 0. Worker 4 set 2: Sample seen 2009600, train loss 0.324424, average computation time 10.278
[INFO] [2017-08-04 05:48:17] Epoch 0. Worker 5 set 2: Sample seen 2009600, train loss 0.324091, average computation time 10.300
[INFO] [2017-08-04 05:48:17] Epoch 0. Worker 6 set 2: Sample seen 2009600, train loss 0.324172, average computation time 10.288
[INFO] [2017-08-04 05:48:17] Epoch 0. Worker 2 set 2: Sample seen 2009600, train loss 0.324817, average computation time 10.295
[INFO] [2017-08-04 05:48:18] Epoch 0. Worker 0 set 2: Sample seen 2009600, train loss 0.324159, average computation time 10.280
[INFO] [2017-08-04 05:48:18] Epoch 0. Worker 7 set 2: Sample seen 2009600, train loss 0.324558, average computation time 10.319
[INFO] [2017-08-04 05:48:18] Epoch 0. Worker 3 set 2: Sample seen 2009600, train loss 0.324725, average computation time 10.305
[INFO] [2017-08-04 05:48:18] Epoch 0. Worker 1 set 2: Sample seen 2009600, train loss 0.324390, average computation time 10.362
[INFO] [2017-08-04 05:48:29] Epoch 0. Worker 5 set 3: Sample seen 3014400, train loss 0.185021, average computation time 10.323
[INFO] [2017-08-04 05:48:30] Epoch 0. Worker 0 set 3: Sample seen 3014400, train loss 0.185054, average computation time 10.292
[INFO] [2017-08-04 05:48:30] Epoch 0. Worker 6 set 3: Sample seen 3014400, train loss 0.184908, average computation time 10.300
[INFO] [2017-08-04 05:48:30] Epoch 0. Worker 4 set 3: Sample seen 3014400, train loss 0.185410, average computation time 10.294
[INFO] [2017-08-04 05:48:31] Epoch 0. Worker 3 set 3: Sample seen 3014400, train loss 0.185406, average computation time 10.322
[INFO] [2017-08-04 05:48:31] Epoch 0. Worker 7 set 3: Sample seen 3014400, train loss 0.185430, average computation time 10.333
[INFO] [2017-08-04 05:48:30] Epoch 0. Worker 2 set 3: Sample seen 3014400, train loss 0.185883, average computation time 10.309
[INFO] [2017-08-04 05:48:31] Epoch 0. Worker 1 set 3: Sample seen 3014400, train loss 0.185182, average computation time 10.370
[INFO] [2017-08-04 05:48:44] Epoch 0. Worker 6 set 4: Sample seen 4019200, train loss 0.184885, average computation time 10.321
[INFO] [2017-08-04 05:48:44] Epoch 0. Worker 5 set 4: Sample seen 4019200, train loss 0.185955, average computation time 10.334
[INFO] [2017-08-04 05:48:44] Epoch 0. Worker 4 set 4: Sample seen 4019200, train loss 0.185493, average computation time 10.305
[INFO] [2017-08-04 05:48:44] Epoch 0. Worker 0 set 4: Sample seen 4019200, train loss 0.184199, average computation time 10.298
[INFO] [2017-08-04 05:48:45] Epoch 0. Worker 7 set 4: Sample seen 4019200, train loss 0.184799, average computation time 10.339
[INFO] [2017-08-04 05:48:44] Epoch 0. Worker 2 set 4: Sample seen 4019200, train loss 0.186085, average computation time 10.316
[INFO] [2017-08-04 05:48:45] Epoch 0. Worker 1 set 4: Sample seen 4019200, train loss 0.185724, average computation time 10.382
[INFO] [2017-08-04 05:48:45] Epoch 0. Worker 3 set 4: Sample seen 4019200, train loss 0.185794, average computation time 10.325
[INFO] [2017-08-04 05:48:56] Epoch 0. Worker 5 set 5: Sample seen 5024000, train loss 0.186345, average computation time 10.341
[INFO] [2017-08-04 05:48:56] Epoch 0. Worker 4 set 5: Sample seen 5024000, train loss 0.184586, average computation time 10.310
[INFO] [2017-08-04 05:48:56] Epoch 0. Worker 6 set 5: Sample seen 5024000, train loss 0.185357, average computation time 10.326
[INFO] [2017-08-04 05:48:57] Epoch 0. Worker 0 set 5: Sample seen 5024000, train loss 0.186646, average computation time 10.303
[INFO] [2017-08-04 05:48:57] Epoch 0. Worker 2 set 5: Sample seen 5024000, train loss 0.185403, average computation time 10.321
[INFO] [2017-08-04 05:48:58] Epoch 0. Worker 7 set 5: Sample seen 5024000, train loss 0.185726, average computation time 10.341
[INFO] [2017-08-04 05:48:58] Epoch 0. Worker 3 set 5: Sample seen 5024000, train loss 0.184553, average computation time 10.329
[INFO] [2017-08-04 05:48:58] Epoch 0. Worker 1 set 5: Sample seen 5024000, train loss 0.185833, average computation time 10.407
[INFO] [2017-08-04 05:49:11] Epoch 0. Worker 0 set 6: Sample seen 6028800, train loss 0.184601, average computation time 10.305
[INFO] [2017-08-04 05:49:11] Epoch 0. Worker 6 set 6: Sample seen 6028800, train loss 0.185056, average computation time 10.328
[INFO] [2017-08-04 05:49:11] Epoch 0. Worker 4 set 6: Sample seen 6028800, train loss 0.185954, average computation time 10.315
[INFO] [2017-08-04 05:49:11] Epoch 0. Worker 7 set 6: Sample seen 6028800, train loss 0.185023, average computation time 10.342
[INFO] [2017-08-04 05:49:12] Epoch 0. Worker 3 set 6: Sample seen 6028800, train loss 0.184515, average computation time 10.333
[INFO] [2017-08-04 05:49:11] Epoch 0. Worker 2 set 6: Sample seen 6028800, train loss 0.185445, average computation time 10.323
[INFO] [2017-08-04 05:49:11] Epoch 0. Worker 5 set 6: Sample seen 6028800, train loss 0.185955, average computation time 10.339
[INFO] [2017-08-04 05:49:12] Epoch 0. Worker 1 set 6: Sample seen 6028800, train loss 0.184124, average computation time 10.400
[INFO] [2017-08-04 05:49:23] Epoch 0. Worker 6 set 7: Sample seen 7033600, train loss 0.185179, average computation time 10.324
[INFO] [2017-08-04 05:49:23] Epoch 0. Worker 4 set 7: Sample seen 7033600, train loss 0.185616, average computation time 10.319
[INFO] [2017-08-04 05:49:23] Epoch 0. Worker 0 set 7: Sample seen 7033600, train loss 0.184993, average computation time 10.307
[INFO] [2017-08-04 05:49:23] Epoch 0. Worker 2 set 7: Sample seen 7033600, train loss 0.185800, average computation time 10.327
[INFO] [2017-08-04 05:49:24] Epoch 0. Worker 3 set 7: Sample seen 7033600, train loss 0.185309, average computation time 10.337
[INFO] [2017-08-04 05:49:24] Epoch 0. Worker 7 set 7: Sample seen 7033600, train loss 0.185553, average computation time 10.343
[INFO] [2017-08-04 05:49:24] Epoch 0. Worker 5 set 7: Sample seen 7033600, train loss 0.184794, average computation time 10.344
[INFO] [2017-08-04 05:49:25] Epoch 0. Worker 1 set 7: Sample seen 7033600, train loss 0.185832, average computation time 10.401
[INFO] [2017-08-04 05:49:37] Epoch 0. Worker 6 set 8: Sample seen 8038400, train loss 0.185100, average computation time 10.326
[INFO] [2017-08-04 05:49:37] Epoch 0. Worker 4 set 8: Sample seen 8038400, train loss 0.184354, average computation time 10.320
[INFO] [2017-08-04 05:49:38] Epoch 0. Worker 0 set 8: Sample seen 8038400, train loss 0.184852, average computation time 10.310
[INFO] [2017-08-04 05:49:37] Epoch 0. Worker 2 set 8: Sample seen 8038400, train loss 0.185537, average computation time 10.329
[INFO] [2017-08-04 05:49:38] Epoch 0. Worker 7 set 8: Sample seen 8038400, train loss 0.185457, average computation time 10.344
[INFO] [2017-08-04 05:49:38] Epoch 0. Worker 3 set 8: Sample seen 8038400, train loss 0.186510, average computation time 10.336
[INFO] [2017-08-04 05:49:38] Epoch 0. Worker 5 set 8: Sample seen 8038400, train loss 0.186129, average computation time 10.342
[INFO] [2017-08-04 05:49:38] Epoch 0. Worker 1 set 8: Sample seen 8038400, train loss 0.184763, average computation time 10.397
[INFO] [2017-08-04 05:49:52] Epoch 0. Worker 0 set 9: Sample seen 9043200, train loss 0.185466, average computation time 10.312
[INFO] [2017-08-04 05:49:51] Epoch 0. Worker 6 set 9: Sample seen 9043200, train loss 0.185530, average computation time 10.332
[INFO] [2017-08-04 05:49:52] Epoch 0. Worker 5 set 9: Sample seen 9043200, train loss 0.185080, average computation time 10.344
[INFO] [2017-08-04 05:49:52] Epoch 0. Worker 4 set 9: Sample seen 9043200, train loss 0.185828, average computation time 10.320
[INFO] [2017-08-04 05:49:51] Epoch 0. Worker 2 set 9: Sample seen 9043200, train loss 0.185756, average computation time 10.329
[INFO] [2017-08-04 05:49:52] Epoch 0. Worker 7 set 9: Sample seen 9043200, train loss 0.185567, average computation time 10.345
[INFO] [2017-08-04 05:49:52] Epoch 0. Worker 3 set 9: Sample seen 9043200, train loss 0.185541, average computation time 10.340
[INFO] [2017-08-04 05:49:52] Epoch 0. Worker 1 set 9: Sample seen 9043200, train loss 0.184749, average computation time 10.397
[INFO] [2017-08-04 05:50:04] Epoch 0. Worker 6 set 10: Sample seen 10048000, train loss 0.184791, average computation time 10.332
[INFO] [2017-08-04 05:50:04] Epoch 0. Worker 5 set 10: Sample seen 10048000, train loss 0.185043, average computation time 10.338
[INFO] [2017-08-04 05:50:04] Epoch 0. Worker 0 set 10: Sample seen 10048000, train loss 0.186000, average computation time 10.316
[INFO] [2017-08-04 05:50:04] Epoch 0. Worker 4 set 10: Sample seen 10048000, train loss 0.185390, average computation time 10.319
[INFO] [2017-08-04 05:50:04] Epoch 0. Worker 2 set 10: Sample seen 10048000, train loss 0.185236, average computation time 10.332
[INFO] [2017-08-04 05:50:05] Epoch 0. Worker 7 set 10: Sample seen 10048000, train loss 0.185303, average computation time 10.346
[INFO] [2017-08-04 05:50:05] Epoch 0. Worker 3 set 10: Sample seen 10048000, train loss 0.184906, average computation time 10.342
[INFO] [2017-08-04 05:50:05] Epoch 0. Worker 1 set 10: Sample seen 10048000, train loss 0.184893, average computation time 10.399
[INFO] [2017-08-04 05:50:18] Epoch 0. Worker 4 set 11: Sample seen 11052800, train loss 0.184983, average computation time 10.319
[INFO] [2017-08-04 05:50:18] Epoch 0. Worker 0 set 11: Sample seen 11052800, train loss 0.185380, average computation time 10.317
[INFO] [2017-08-04 05:50:18] Epoch 0. Worker 6 set 11: Sample seen 11052800, train loss 0.186278, average computation time 10.344
[INFO] [2017-08-04 05:50:18] Epoch 0. Worker 5 set 11: Sample seen 11052800, train loss 0.186255, average computation time 10.340
[INFO] [2017-08-04 05:50:18] Epoch 0. Worker 7 set 11: Sample seen 11052800, train loss 0.185702, average computation time 10.346
[INFO] [2017-08-04 05:50:18] Epoch 0. Worker 2 set 11: Sample seen 11052800, train loss 0.185706, average computation time 10.332
[INFO] [2017-08-04 05:50:19] Epoch 0. Worker 3 set 11: Sample seen 11052800, train loss 0.184533, average computation time 10.342
[INFO] [2017-08-04 05:50:19] Epoch 0. Worker 1 set 11: Sample seen 11052800, train loss 0.185909, average computation time 10.396
[INFO] [2017-08-04 05:50:30] Epoch 0. Worker 0 set 12: Sample seen 12057600, train loss 0.185668, average computation time 10.318
[INFO] [2017-08-04 05:50:30] Epoch 0. Worker 4 set 12: Sample seen 12057600, train loss 0.185441, average computation time 10.319
[INFO] [2017-08-04 05:50:30] Epoch 0. Worker 6 set 12: Sample seen 12057600, train loss 0.184900, average computation time 10.347
[INFO] [2017-08-04 05:50:30] Epoch 0. Worker 5 set 12: Sample seen 12057600, train loss 0.185093, average computation time 10.336
[INFO] [2017-08-04 05:50:31] Epoch 0. Worker 7 set 12: Sample seen 12057600, train loss 0.185011, average computation time 10.347
[INFO] [2017-08-04 05:50:31] Epoch 0. Worker 2 set 12: Sample seen 12057600, train loss 0.186025, average computation time 10.331
[INFO] [2017-08-04 05:50:31] Epoch 0. Worker 3 set 12: Sample seen 12057600, train loss 0.185583, average computation time 10.342
[INFO] [2017-08-04 05:50:32] Epoch 0. Worker 1 set 12: Sample seen 12057600, train loss 0.184661, average computation time 10.403
[INFO] [2017-08-04 05:50:45] Epoch 0. Worker 4 set 13: Sample seen 13062400, train loss 0.184657, average computation time 10.318
[INFO] [2017-08-04 05:50:45] Epoch 0. Worker 6 set 13: Sample seen 13062400, train loss 0.184768, average computation time 10.346
[INFO] [2017-08-04 05:50:45] Epoch 0. Worker 0 set 13: Sample seen 13062400, train loss 0.185379, average computation time 10.318
[INFO] [2017-08-04 05:50:45] Epoch 0. Worker 7 set 13: Sample seen 13062400, train loss 0.184864, average computation time 10.349
[INFO] [2017-08-04 05:50:46] Epoch 0. Worker 5 set 13: Sample seen 13062400, train loss 0.184797, average computation time 10.338
[INFO] [2017-08-04 05:50:45] Epoch 0. Worker 2 set 13: Sample seen 13062400, train loss 0.185100, average computation time 10.329
[INFO] [2017-08-04 05:50:46] Epoch 0. Worker 3 set 13: Sample seen 13062400, train loss 0.185819, average computation time 10.342
[INFO] [2017-08-04 05:50:46] Epoch 0. Worker 1 set 13: Sample seen 13062400, train loss 0.185333, average computation time 10.398
[INFO] [2017-08-04 05:50:57] Epoch 0. Worker 4 set 14: Sample seen 14067200, train loss 0.184620, average computation time 10.318
[INFO] [2017-08-04 05:50:57] Epoch 0. Worker 5 set 14: Sample seen 14067200, train loss 0.185736, average computation time 10.337
[INFO] [2017-08-04 05:50:57] Epoch 0. Worker 6 set 14: Sample seen 14067200, train loss 0.184984, average computation time 10.348
[INFO] [2017-08-04 05:50:58] Epoch 0. Worker 0 set 14: Sample seen 14067200, train loss 0.184575, average computation time 10.320
[INFO] [2017-08-04 05:50:58] Epoch 0. Worker 2 set 14: Sample seen 14067200, train loss 0.185090, average computation time 10.328
[INFO] [2017-08-04 05:50:58] Epoch 0. Worker 7 set 14: Sample seen 14067200, train loss 0.185093, average computation time 10.350
[INFO] [2017-08-04 05:50:59] Epoch 0. Worker 3 set 14: Sample seen 14067200, train loss 0.186137, average computation time 10.343
[INFO] [2017-08-04 05:51:00] Epoch 0. Worker 1 set 14: Sample seen 14067200, train loss 0.186218, average computation time 10.402
[INFO] [2017-08-04 05:51:10] Finish train, total sample 14963129
[INFO] [2017-08-04 05:51:11] Finish train, total sample 14963129
[INFO] [2017-08-04 05:51:10] Finish train, total sample 14963130
[INFO] [2017-08-04 05:51:11] Finish train, total sample 14963129
[INFO] [2017-08-04 05:51:10] Finish train, total sample 14963129
[INFO] [2017-08-04 05:51:11] Finish train, total sample 14963129
[INFO] [2017-08-04 05:51:11] Finish train, total sample 14963129
[INFO] [2017-08-04 05:51:11] Finish train, total sample 14963129
[INFO] [2017-08-04 05:51:12] Multiverso Shutdown successfully
[INFO] [2017-08-04 05:51:12] Multiverso Shutdown successfully
[INFO] [2017-08-04 05:51:11] Multiverso Shutdown successfully
[INFO] [2017-08-04 05:51:11] Multiverso Shutdown successfully
[INFO] [2017-08-04 05:51:12] Multiverso Shutdown successfully
[INFO] [2017-08-04 05:51:11] Multiverso Shutdown successfully
[INFO] [2017-08-04 05:51:11] Multiverso Shutdown successfully
[INFO] [2017-08-04 05:51:11] Multiverso Shutdown successfully
