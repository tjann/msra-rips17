parent: $LVSR/exp/billion_words/configs/autoencoder.yaml
training:
    rules:
        - adam
    scale: 0.001
    momentum: 0.9
    decay_rate: 0.999
    epsilon: 1.e-6
data:
    clip_length: 12
    force_eos_when_clipping: True
    corrupt_sources:
        names: ["inputs"]
        probs: [0.5]
stages:
    main:
        number: 50
        training:
            num_batches: 400000
    annealing:
        number: 100
        training:
            num_batches: 200000
            scale: 0.0001
